{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3265255-2fbf-4bfe-847b-cfd7c6197107",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using the torchcam algorithm library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd1eb3-8146-4f36-acf4-0e6fb68c47ca",
   "metadata": {},
   "source": [
    "## Importing the Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344d4d0-da96-44de-ac73-4e5fa539e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4c953-0fb7-4c8a-8a27-d0043d13d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf torch-cam # if you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00986990-975a-4766-b3f5-7202a7ad463e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install torch-cam\n",
    "!git clone https://github.com/frgfm/torch-cam.git \n",
    "!pip install -e torch-cam/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd600a36-1d04-4d96-a6b7-b1aca7a3da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c982d7c-ded9-4750-84f7-2739044965aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed749b0b-7643-4da5-95be-5b8dbce42c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c011a51-4054-4617-b6a0-e894e5a6ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/(18-1-91).pth')#Import the trained classification model.\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191ce88-a95d-4bba-8244-cd93b177eb49",
   "metadata": {},
   "source": [
    "## Import CAM methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ada875-b1e9-44f7-aed9-ee731bb4151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcam.methods import SSCAM\n",
    "cam_extractor = SSCAM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9f054-79bc-4560-a43d-8c34d4869945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms  #Image preprocessing: scaling, cropping, conversion to Tensor, normalisation\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ab9454-725d-4e41-8f02-4229fcc419bb",
   "metadata": {},
   "source": [
    "## Generate heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541394d7-995f-460b-b85a-ffda018fd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchcam.utils import overlay_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38570cf5-62e8-46b2-9e28-0d1197a86a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -iname '.ipynb_checkpoints'#Delete redundant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15197f-f7a7-4d5b-9621-01a731630772",
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `find . -iname '.ipynb_checkpoints'`; do rm -rf $i;done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a378dc-4552-4a63-8e7a-7c4c5396fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -iname '.ipynb_checkpoints'#Look again for redundant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37e87a-b4e2-4b9f-a7e3-cf2f7c0b1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'test'#The location where the test images are stored.\n",
    "for files in os.listdir(img_path):\n",
    "    imgpath = img_path + '/' + files\n",
    "    img_pil = Image.open(imgpath)\n",
    "    input_tensor = test_transform(img_pil).unsqueeze(0).to(device)\n",
    "    pred_logits = model(input_tensor)\n",
    "    pred_id = torch.topk(pred_logits, 1)[1].detach().cpu().numpy().squeeze().item()\n",
    "    activation_map = cam_extractor(pred_id, pred_logits)\n",
    "    activation_map = activation_map[0][0].detach().cpu().numpy()\n",
    "    result = overlay_mask(img_pil, Image.fromarray(activation_map), alpha=0.001)\n",
    "    path2 = '228sscam' + '/' + files #The location where the post-prediction results are stored.\n",
    "    result.save(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9150e2-4eba-47bd-b9cf-23177a909dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
