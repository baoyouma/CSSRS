{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3265255-2fbf-4bfe-847b-cfd7c6197107",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using the torchcam algorithm library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd1eb3-8146-4f36-acf4-0e6fb68c47ca",
   "metadata": {},
   "source": [
    "## Importing the Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a344d4d0-da96-44de-ac73-4e5fa539e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c4c953-0fb7-4c8a-8a27-d0043d13d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf torch-cam # if you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00986990-975a-4766-b3f5-7202a7ad463e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'torch-cam'...\n",
      "remote: Enumerating objects: 6167, done.\u001b[K\n",
      "remote: Counting objects: 100% (1705/1705), done.\u001b[K\n",
      "remote: Compressing objects: 100% (623/623), done.\u001b[K\n",
      "remote: Total 6167 (delta 1188), reused 1550 (delta 1072), pack-reused 4462\u001b[K\n",
      "接收对象中: 100% (6167/6167), 9.63 MiB | 3.83 MiB/s, 完成.\n",
      "处理 delta 中: 100% (4250/4250), 完成.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Obtaining file:///home/featurize/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/6-%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E5%88%86%E6%9E%90%E3%80%81%E6%98%BE%E8%91%97%E6%80%A7%E5%88%86%E6%9E%90/1.torch-cam%E5%B7%A5%E5%85%B7%E5%8C%85%EF%BC%9ACAM%E7%83%AD%E5%8A%9B%E5%9B%BE/torch-cam\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=8.3.2 in /environment/miniconda3/lib/python3.7/site-packages (from torchcam==0.4.0.dev0) (8.4.0)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.7.0 in /environment/miniconda3/lib/python3.7/site-packages (from torchcam==0.4.0.dev0) (1.10.0+cu113)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.14.0 in /environment/miniconda3/lib/python3.7/site-packages (from torchcam==0.4.0.dev0) (1.21.4)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /environment/miniconda3/lib/python3.7/site-packages (from torchcam==0.4.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /environment/miniconda3/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /environment/miniconda3/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /environment/miniconda3/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /environment/miniconda3/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (4.28.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /environment/miniconda3/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /environment/miniconda3/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (3.0.6)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /environment/miniconda3/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (6.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /environment/miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /environment/miniconda3/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /environment/miniconda3/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib<4.0.0,>=3.0.0->torchcam==0.4.0.dev0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: typing-extensions in /environment/miniconda3/lib/python3.7/site-packages (from torch<2.0.0,>=1.7.0->torchcam==0.4.0.dev0) (4.0.1)\n",
      "Installing collected packages: torchcam\n",
      "  Running setup.py develop for torchcam\n",
      "Successfully installed torchcam-0.4.0.dev0\n"
     ]
    }
   ],
   "source": [
    "# Install torch-cam\n",
    "!git clone https://github.com/frgfm/torch-cam.git \n",
    "!pip install -e torch-cam/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd600a36-1d04-4d96-a6b7-b1aca7a3da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c982d7c-ded9-4750-84f7-2739044965aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed749b0b-7643-4da5-95be-5b8dbce42c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c011a51-4054-4617-b6a0-e894e5a6ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/(18-1-91).pth')#Import the trained classification model.\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191ce88-a95d-4bba-8244-cd93b177eb49",
   "metadata": {},
   "source": [
    "## Import CAM methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ada875-b1e9-44f7-aed9-ee731bb4151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:no value was provided for `target_layer`, thus set to 'layer4'.\n"
     ]
    }
   ],
   "source": [
    "from torchcam.methods import SSCAM\n",
    "cam_extractor = SSCAM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10b9f054-79bc-4560-a43d-8c34d4869945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms  #Image preprocessing: scaling, cropping, conversion to Tensor, normalisation\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ab9454-725d-4e41-8f02-4229fcc419bb",
   "metadata": {},
   "source": [
    "## Generate heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541394d7-995f-460b-b85a-ffda018fd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchcam.utils import overlay_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38570cf5-62e8-46b2-9e28-0d1197a86a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: paths must precede expression: `redundant'\n"
     ]
    }
   ],
   "source": [
    "!find . -iname '.ipynb_checkpoints'#Delete redundant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc15197f-f7a7-4d5b-9621-01a731630772",
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `find . -iname '.ipynb_checkpoints'`; do rm -rf $i;done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78a378dc-4552-4a63-8e7a-7c4c5396fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -iname '.ipynb_checkpoints'#Look again for redundant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f37e87a-b4e2-4b9f-a7e3-cf2f7c0b1265",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18464/4064139647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpred_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mactivation_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mactivation_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlay_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/图像分类/6-可解释性分析、显著性分析/1.torch-cam工具包：CAM热力图/torch-cam/torchcam/methods/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, class_idx, scores, normalized, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Compute CAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_cams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     def compute_cams(\n",
      "\u001b[0;32m~/图像分类/6-可解释性分析、显著性分析/1.torch-cam工具包：CAM热力图/torch-cam/torchcam/methods/core.py\u001b[0m in \u001b[0;36mcompute_cams\u001b[0;34m(self, class_idx, scores, normalized, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# Get map weight & unsqueeze it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mcams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/miniconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/图像分类/6-可解释性分析、显著性分析/1.torch-cam工具包：CAM热力图/torch-cam/torchcam/methods/activation.py\u001b[0m in \u001b[0;36m_get_weights\u001b[0;34m(self, class_idx, *args)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_score_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupsampled_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Reenable hook updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/miniconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/图像分类/6-可解释性分析、显著性分析/1.torch-cam工具包：CAM热力图/torch-cam/torchcam/methods/activation.py\u001b[0m in \u001b[0;36m_get_score_weights\u001b[0;34m(self, activations, class_idx)\u001b[0m\n\u001b[1;32m    323\u001b[0m                     \u001b[0m_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0;31m# Get the softmax probabilities of the target class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     \u001b[0mcic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscored_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_path = 'test'#The location where the test images are stored.\n",
    "for files in os.listdir(img_path):\n",
    "    imgpath = img_path + '/' + files\n",
    "    img_pil = Image.open(imgpath)\n",
    "    input_tensor = test_transform(img_pil).unsqueeze(0).to(device)\n",
    "    pred_logits = model(input_tensor)\n",
    "    pred_id = torch.topk(pred_logits, 1)[1].detach().cpu().numpy().squeeze().item()\n",
    "    activation_map = cam_extractor(pred_id, pred_logits)\n",
    "    activation_map = activation_map[0][0].detach().cpu().numpy()\n",
    "    result = overlay_mask(img_pil, Image.fromarray(activation_map), alpha=0.001)\n",
    "    path2 = '228sscam' + '/' + files #The location where the post-prediction results are stored.\n",
    "    result.save(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9150e2-4eba-47bd-b9cf-23177a909dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
